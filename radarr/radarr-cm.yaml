apiVersion: v1
kind: ConfigMap
metadata:
  name: radarr-cm
  namespace: radarr
data:
  tarcopy.sh: |
    #!/bin/sh
    echo "Starting job at $(date)"
    tar -czf /nfs/radarr_backup_$(date +%Y_%m_%d_%H_%M_%S).tar.gz /pvc
    echo "Job completed at $(date)"
  init-pvc-bound.sh: |
    #!/bin/sh
    echo "Waiting for PVC to be bound..."
    until [ "$(kubectl get pvc radarr-pvc -n radarr -o jsonpath='{.status.phase}')" = "Bound" ]; do
      echo "PVC not bound yet. Waiting..."
      sleep 2
    done
    echo "PVC is bound."
  radarr-volumesnapshot-tarshot.yaml: |
    apiVersion: snapshot.storage.k8s.io/v1
    kind: VolumeSnapshot
    metadata:
      name: radarr-volumesnapshot-tarshot
      namespace: radarr
    spec:
      volumeSnapshotClassName: rook-cephfs-snapshot-class
      source:
        persistentVolumeClaimName: radarr-pvc
  radarr-pvc-tarshot.yaml: |
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: radarr-pvc-tarshot
      namespace: radarr
    spec:
      accessModes:
      - ReadWriteMany
      resources:
        requests:
          storage: 100Gi
      storageClassName: rook-cephfs
      dataSource:
        name: radarr-volumesnapshot-tarshot
        kind: VolumeSnapshot
        apiGroup: snapshot.storage.k8s.io
  radarr-job-tarshot.yaml: |
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: radarr-job-tarshot
      namespace: radarr
    spec:
      template:
        spec:
          containers:
          - name: tarcopy
            image: busybox
            command: ["sh", "/scripts/tarcopy.sh"]
            securityContext:
              runAsUser: 568
              runAsGroup: 568
            volumeMounts:
            - name: pvc
              mountPath: /pvc
            - name: nfs
              mountPath: /nfs
            - name: script
              mountPath: /scripts
          restartPolicy: OnFailure
          volumes:
          - name: pvc
            persistentVolumeClaim:
              claimName: radarr-pvc-tarshot
          - name: nfs
            nfs:
              server: 192.168.0.100
              path: /mnt/epool/tarshot/radarr
          - name: script
            configMap:
              name: radarr-cm
              defaultMode: 0755
  tarshot.sh: |
    #!/bin/sh
    set -e

    log() {
      echo "$(date +'%Y-%m-%d %H:%M:%S') - $1"
    }

    remove_finalizers() {
      resource_type=$1
      resource_name=$2
      namespace=$3

      log "Removing finalizers from $resource_type $resource_name"
      kubectl patch $resource_type $resource_name -n $namespace --type=json -p '[{"op": "remove", "path": "/metadata/finalizers"}]' && log "Finalizers removed from $resource_type $resource_name"
    }

    cleanup_assets() {
      force_flag=$1
      log "Starting cleanup of assets..."

      # Check and delete VolumeSnapshot
      if kubectl get volumesnapshot radarr-volumesnapshot-tarshot -n radarr > /dev/null 2>&1; then
        remove_finalizers volumesnapshot radarr-volumesnapshot-tarshot radarr
        log "Deleting VolumeSnapshot"
        kubectl delete volumesnapshot radarr-volumesnapshot-tarshot -n radarr $force_flag && log "VolumeSnapshot deleted"
      else
        log "VolumeSnapshot does not exist"
      fi

      # Check and delete PVC
      if kubectl get pvc radarr-pvc-tarshot -n radarr > /dev/null 2>&1; then
        remove_finalizers pvc radarr-pvc-tarshot radarr
        log "Deleting PVC"
        kubectl delete pvc radarr-pvc-tarshot -n radarr $force_flag && log "PVC deleted"
      else
        log "PVC does not exist"
      fi

      # Check and delete Job
      if kubectl get job radarr-job-tarshot -n radarr > /dev/null 2>&1; then
        log "Deleting Job"
        kubectl delete job radarr-job-tarshot -n radarr $force_flag && log "Job deleted"
      else
        log "Job does not exist"
      fi

      log "Assets cleanup completed"
    }

    log "Starting backup job..."

    # Pre-cleanup with force flag
    cleanup_assets "--force"

    # Step 1: Create new assets
    ### VolumeSnapshot ###
    log "Applying VolumeSnapshot configuration" && kubectl apply -f /scripts/radarr-volumesnapshot-tarshot.yaml
    while [ "$(kubectl get volumesnapshot radarr-volumesnapshot-tarshot -n radarr -o jsonpath='{.status.readyToUse}')" != "true" ]; do
      log "Waiting for the VolumeSnapshot to be ready..."
      sleep 10
    done

    ### PVC ###
    log "Applying PVC configuration" && kubectl apply -f /scripts/radarr-pvc-tarshot.yaml
    while [ "$(kubectl get pvc radarr-pvc-tarshot -n radarr -o jsonpath='{.status.phase}')" != "Bound" ]; do
      log "Waiting for the PVC to be bound..."
      sleep 10
    done

    ### JOB ###
    log "Applying Job configuration" && kubectl apply -f /scripts/radarr-job-tarshot.yaml
    while [ "$(kubectl get job radarr-job-tarshot -n radarr -o jsonpath='{.status.succeeded}')" != "1" ]; do
      log "Waiting for the Job to complete..."
      sleep 10
    done

    log "Backup job completed"

    # Post-cleanup without force flag
    cleanup_assets "--force"

    log "Script execution completed"
